{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/e7/5258cb787dc036f419ec57491decf8bfa89ab52c401b08b4b9228e43dc4c/xgboost-0.81-py2.py3-none-win_amd64.whl (7.4MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from xgboost) (1.14.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.81\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/9f/f6324af3fc43f352e568b5850695c30ed7dd14af06a94f97953ff9187569/hyperopt-0.1.1-py3-none-any.whl (117kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from hyperopt) (1.1.0)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from hyperopt) (1.14.3)\n",
      "Collecting pymongo (from hyperopt)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/25/44b0fc81668a883739b108d9bd0c95b24f0b0204cb2dc93e0f259e173670/pymongo-3.7.2-cp36-cp36m-win_amd64.whl (315kB)\n",
      "Requirement already satisfied: six in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from hyperopt) (1.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from hyperopt) (2.1)\n",
      "Requirement already satisfied: decorator>=4.1.0 in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from networkx->hyperopt) (4.3.0)\n",
      "Building wheels for collected packages: future\n",
      "  Running setup.py bdist_wheel for future: started\n",
      "  Running setup.py bdist_wheel for future: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\NastyaOmen\\AppData\\Local\\pip\\Cache\\wheels\\0c\\61\\d2\\d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built future\n",
      "Installing collected packages: future, pymongo, hyperopt\n",
      "Successfully installed future-0.17.1 hyperopt-0.1.1 pymongo-3.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from seaborn) (1.14.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from seaborn) (0.23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from matplotlib->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from matplotlib->seaborn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from matplotlib->seaborn) (2.7.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from matplotlib->seaborn) (2018.4)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from matplotlib->seaborn) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from matplotlib->seaborn) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nastyaomen\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->seaborn) (39.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Импортируем нужные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Алгоритм бустинга, идея в том, что мы берем много не очень сильных алгоритмов и усредняем спец образом\n",
    "import xgboost as xgb\n",
    "\n",
    "#Библиотека для автоматического подбора параметров\n",
    "\n",
    "import hyperopt as hp\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#Многие алгоритмы имеют элемент псевдослучайности - фиксируем эту случайность, чтобы результаты были воспроизводимы\n",
    "SEED = 13\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_processing_obj(df, main_df=None):\n",
    "    #df - датафрейм, который обрабатывается\n",
    "    #main_df - датафрейм, на основании когторого обрабатываем, пропуски на тесте заполянем за счет трейна\n",
    "    if main_df is None:\n",
    "        main_df = df\n",
    "    #Возраст в годах \n",
    "    #Что можно: разбить на бины ( от 10 до 20, от 20 до 30 итд)\n",
    "    df['age_year'] = df.age / 365\n",
    "    #LabelПризнаки приведем к 0..n\n",
    "    df['sex'] = np.where(df.gender == 2, 0, 1)\n",
    "    df.drop(['id', 'alco', 'active', 'smoke', 'age', 'gender'], axis=1, inplace=True)\n",
    "    rcols = ['height', 'weight', 'ap_hi', 'ap_lo', 'age_year']\n",
    "    \n",
    "    #Генерируем небольшие фичи\n",
    "    df['ap_hi_200'] = df.ap_hi - 200\n",
    "    df['por_al'] = round(df.ap_lo / df.ap_hi, 2)\n",
    "    df['por_weight'] = round(df.height / df.weight, 2)\n",
    "    df['mean_'+ 'por_al'] = round(df['por_al'] - df['por_al'].mean(),2)\n",
    "    df['mean_'+ 'por_weight'] = round(df['por_weight'] - df['por_weight'].mean(),2)\n",
    "    for col in tqdm(rcols):\n",
    "        if col!='ap_lo':\n",
    "            df['log_'+col] = round(np.log(df[col]),2)\n",
    "        df['mean_'+col] = round(df[col] - df[col].mean(),2)\n",
    "        df[col] = round(df[col], 2)\n",
    "        for col_2 in rcols:\n",
    "            if col != col_2:\n",
    "                df[col+'+'+col_2] = df[col]+df[col_2]\n",
    "                df[col+'-'+col_2] = df[col]-df[col_2]\n",
    "    df['bad_mean_diff_heigh'] = round(df.height - main_df[main_df.cardio==0].height.mean(), 2)\n",
    "    df['good_mean_diff_heigh'] = round(df.height - main_df[main_df.cardio==1].height.mean(), 2)\n",
    "    df['bad_mean_diff_weight'] = round(df.weight - main_df[main_df.cardio==0].weight.mean(), 2)\n",
    "    df['good_mean_diff_weight'] = round(df.weight - main_df[main_df.cardio==1].weight.mean(), 2)\n",
    "    df['bad_mean_diff_ap_hi'] = round(df.ap_hi - main_df[main_df.cardio==0].ap_hi.mean(), 2)\n",
    "    df['good_mean_diff_ap_hi'] = round(df.ap_hi - main_df[main_df.cardio==1].ap_hi.mean(), 2)\n",
    "    df['bad_mean_diff_ap_lo'] = round(df.ap_lo - main_df[main_df.cardio==0].ap_lo.mean(), 2)\n",
    "    df['good_mean_diff_ap_lo'] = round(df.ap_lo - main_df[main_df.cardio==1].ap_lo.mean(), 2)\n",
    "    df['bad_mean_diff_frac_pressure'] = round(df.por_al - main_df[main_df.cardio==0].por_al.mean(), 2)\n",
    "    df['good_mean_diff_frac_pressure'] = round(df.por_al - main_df[main_df.cardio==1].por_al.mean(), 2)\n",
    "    df['bad_mean_diff_frac_hw'] = round(df.por_weight - main_df[main_df.cardio==0].por_weight.mean(), 2)\n",
    "    df['good_mean_diff_frac_hw'] = round(df.por_weight - main_df[main_df.cardio==1].por_weight.mean(), 2)\n",
    "    df['chol_1'] = np.where(df.cholesterol == 1, 1, 0)\n",
    "    df['chol_2'] = np.where(df.cholesterol == 2, 1, 0)\n",
    "    df['chol_3'] = np.where(df.cholesterol == 3, 1, 0)\n",
    "    df['gl_1'] = np.where(df.gluc == 1, 1, 0)\n",
    "    df['gl_2'] = np.where(df.gluc == 2, 1, 0)\n",
    "    df['gl_3'] = np.where(df.gluc == 3, 1, 0)\n",
    "    df.drop(['cholesterol', 'gluc'], axis=1, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df    \n",
    "\n",
    "def first_scler_obj(df, stdScaler = None, mmScaler = None):\n",
    "    #Давайте посмотрим какая нормализация лучше - выполним и ту и ту\n",
    "    if stdScaler is None:\n",
    "        stdScaler = StandardScaler()\n",
    "        scaled_std = pd.DataFrame(stdScaler.fit_transform(df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).values),\n",
    "                          columns=[i+'_std' for i in df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).columns])\n",
    "    else:\n",
    "        scaled_std = pd.DataFrame(stdScaler.transform(df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).values),\n",
    "                          columns=[i+'_std' for i in df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).columns])\n",
    "    if mmScaler is None:\n",
    "        mmScaler = MinMaxScaler()\n",
    "        scaled_mm = pd.DataFrame(mmScaler.fit_transform(df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).values),\n",
    "                          columns=[i+'_mm' for i in df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).columns])\n",
    "    else:\n",
    "        scaled_mm = pd.DataFrame(mmScaler.transform(df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).values),\n",
    "                          columns=[i+'_mm' for i in df.drop(['chol_1', 'chol_2', 'chol_3', 'gl_1', 'gl_2', 'gl_3','sex'], axis=1).columns])\n",
    "    return stdScaler, mmScaler, pd.concat([scaled_mm, scaled_std, df[['sex', 'chol_1', 'chol_2', 'chol_3',\n",
    "                                               'gl_1','gl_2','gl_3']]], axis=1)\n",
    "\n",
    "def bad_data_replacer(df):\n",
    "    #Ручная чистилка данных\n",
    "    for i in tqdm(range(len(df))):\n",
    "        if df.loc[i, 'ap_hi'] == 906:\n",
    "                df.loc[i, 'ap_lo'] = 60\n",
    "                df.loc[i, 'ap_hi'] = 90\n",
    "        if df.loc[i, 'ap_lo'] <= 40:\n",
    "            if df.loc[i, 'ap_lo']==20 or df.loc[i, 'ap_lo']==30 or df.loc[i, 'ap_lo'] == 0:\n",
    "                df.loc[i, 'ap_lo'] = 80\n",
    "            elif df.loc[i, 'ap_lo']>0 and df.loc[i, 'ap_lo']<=10:\n",
    "                df.loc[i, 'ap_lo'] = df.loc[i, 'ap_lo']*10\n",
    "            elif df.loc[i, 'ap_lo'] < 0:\n",
    "                df.loc[i, 'ap_lo'] = df.loc[i, 'ap_lo'] * -1\n",
    "            else:\n",
    "                df.loc[i, 'ap_lo'] = df.loc[i, 'ap_hi'] - 50\n",
    "        if df.loc[i, 'ap_lo'] > 200:\n",
    "            df.loc[i, 'ap_lo'] = df.loc[i, 'ap_lo'] /10\n",
    "        \n",
    "        if df.loc[i, 'ap_hi'] > 0 and df.loc[i, 'ap_hi'] <= 25:\n",
    "            df.loc[i, 'ap_hi'] = df.loc[i, 'ap_hi'] * 10\n",
    "        if df.loc[i, 'ap_hi'] < 0:\n",
    "            df.loc[i, 'ap_hi'] = df.loc[i, 'ap_hi'] * -1\n",
    "        if df.loc[i, 'ap_hi'] > 250:\n",
    "            if df.loc[i, 'ap_hi'] < 10000:\n",
    "                df.loc[i, 'ap_hi'] = df.loc[i, 'ap_hi'] / 10\n",
    "            else:\n",
    "                df.loc[i, 'ap_hi'] = df.loc[i, 'ap_hi'] /100\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ml5/train.csv', delimiter=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:06<00:00, 11193.74it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.5, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=0, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bad_data_replacer(data)\n",
    "train = first_processing_obj(data)\n",
    "main_df = train.copy()\n",
    "label = train.cardio\n",
    "train.drop(['cardio'], axis=1, inplace=True)\n",
    "stdScaler, mmScaler, train = first_scler_obj(train)\n",
    "\n",
    "#Это бейзлайн, но вам надо оценивать качество - сделайте валидацию!\n",
    "base_xgb = xgb.XGBClassifier(subsample=0.5, max_depth=3, gamma=0.5, learning_rate=0.1, reg_alpha=0, reg_lambda=0, min_child_weight=1, n_estimators=100)\n",
    "base_xgb.fit(train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:03<00:00, 9165.73it/s] \n",
      "100%|██████████| 5/5 [00:00<00:00, 84.97it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('ml5/test.csv', delimiter=';')\n",
    "test = bad_data_replacer(test)\n",
    "test = first_processing_obj(test, main_df)\n",
    "_, _, test = first_scler_obj(test, stdScaler=stdScaler, mmScaler=mmScaler)\n",
    "baseline = pd.DataFrame(base_xgb.predict_proba(test))\n",
    "baseline[1].to_csv('baseline16061400.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
